#!/usr/bin/env python3
"""
Engine Structure Analysis: Understanding the fundamental differences between
Perplexity, Google AI, and Bing AI for SEO vs AISO research.
"""
import pandas as pd
import numpy as np

def analyze_engine_structures():
    """Analyze the fundamental structural differences between engines."""

    print("üîç ANALYZING ENGINE STRUCTURE DIFFERENCES")
    print("="*60)

    # Load data
    df = pd.read_csv('ai_serp_analysis.csv')

    print("üìä DATASET OVERVIEW:")
    print(f"Total records: {len(df):,}")
    print(f"Engines: {', '.join(df['Engine'].unique())}")
    print(f"Unique queries: {df['Query_Name'].nunique() if 'Query_Name' in df.columns else 'N/A'}")

    # Analyze each engine's structure
    for engine in df['Engine'].unique():
        engine_data = df[df['Engine'] == engine]
        print(f"\nüîß {engine.upper()} ANALYSIS:")
        print(f"   Records: {len(engine_data):,}")

        # Check for SERP ranking structure
        print(f"   Page Rank Range: {engine_data['Page Rank'].min()}-{engine_data['Page Rank'].max()}")
        print(f"   Has Traditional SERP Rankings: {'Yes' if engine_data['Page Rank'].max() > 10 else 'Limited to 10'}")

        # Analyze URL diversity
        unique_urls = engine_data['Result URL'].nunique() if 'Result URL' in engine_data.columns else 0
        print(f"   Unique URLs: {unique_urls}")
        print(f"   URL Diversity: {unique_urls / len(engine_data):.2f} (unique URLs per result)")

        # Check AI Overview presence
        has_ai_overview = engine_data['AI Overview'].notna().any() if 'AI Overview' in engine_data.columns else False
        print(f"   Has AI Overview: {has_ai_overview}")

        # Check citation structure
        if 'Citation_Order' in engine_data.columns:
            max_citations = engine_data['Citation_Order'].max()
            print(f"   Max Citations: {max_citations}")

        # Title structure analysis
        if 'Result Title' in engine_data.columns:
            empty_titles = engine_data['Result Title'].isna().sum()
            print(f"   Empty Result Titles: {empty_titles}/{len(engine_data)} ({empty_titles/len(engine_data):.1%})")

def identify_fundamental_differences():
    """Identify the core differences that make engines incomparable."""

    print("\nüö® FUNDAMENTAL STRUCTURAL DIFFERENCES:")
    print("="*60)

    df = pd.read_csv('ai_serp_analysis.csv')

    # Perplexity Analysis
    perplexity = df[df['Engine'] == 'Perplexity']
    google_ai = df[df['Engine'] == 'Google AI']
    bing_ai = df[df['Engine'] == 'Bing AI']

    print("üîµ PERPLEXITY:")
    print("   Structure: AI-First Citation System")
    print("   What it returns: AI-generated answer with source citations")
    print("   Ranking: Citations ordered by relevance to AI answer (NOT search ranking)")
    print("   SERP: NO traditional search results - only citations within AI response")
    print("   Page content: All results from Perplexity.ai domain (not actual source pages)")

    if len(perplexity) > 0:
        perplexity_urls = perplexity['Result URL'].value_counts().head()
        print(f"   URL Pattern: All results are citations, not ranked web pages")
        print(f"   Citation Count Range: {perplexity['Citation_Order'].min()}-{perplexity['Citation_Order'].max()}")

    print("\nüîµ GOOGLE AI:")
    print("   Structure: Traditional SERP + AI Overview")
    print("   What it returns: Regular search results + AI-generated overview")
    print("   Ranking: Traditional PageRank-based search rankings")
    print("   SERP: YES traditional 10-blue-links + AI Overview on top")
    print("   Page content: Actual web pages from diverse domains")

    if len(google_ai) > 0:
        google_domains = google_ai['Result URL'].str.extract(r'https?://([^/]+)')[0].value_counts().head()
        print(f"   Domain Diversity: {google_ai['Result URL'].str.extract(r'https?://([^/]+)')[0].nunique()} unique domains")

    print("\nüîµ BING AI:")
    print("   Structure: Traditional SERP + AI Chat")
    print("   What it returns: Regular search results + Copilot AI response")
    print("   Ranking: Traditional search rankings")
    print("   SERP: YES traditional search results + AI chat interface")
    print("   Page content: Actual web pages from diverse domains")

    if len(bing_ai) > 0:
        bing_domains = bing_ai['Result URL'].str.extract(r'https?://([^/]+)')[0].value_counts().head()
        print(f"   Domain Diversity: {bing_ai['Result URL'].str.extract(r'https?://([^/]+)')[0].nunique()} unique domains")

def create_comparison_plan():
    """Create a plan for handling the different engine types."""

    print("\nüí° ANALYSIS PLAN RECOMMENDATIONS:")
    print("="*60)

    print("üéØ THE CORE PROBLEM:")
    print("   Perplexity is fundamentally different from Google AI and Bing AI.")
    print("   It's not a search engine - it's an AI answer engine with citations.")
    print("   Comparing 'Page Rank' across engines is meaningless because:")
    print("     ‚Ä¢ Google AI/Bing AI: Page Rank = traditional search ranking (1-10+)")
    print("     ‚Ä¢ Perplexity: 'Page Rank' = citation order in AI answer (not search rank)")

    print("\nüîß METHODOLOGICAL OPTIONS:")

    print("\n   OPTION 1: Exclude Perplexity from Ranking Analysis")
    print("   ‚úÖ Pros:")
    print("     ‚Ä¢ Maintains scientific validity")
    print("     ‚Ä¢ Google AI vs Bing AI is a fair comparison (both have traditional SERPs)")
    print("     ‚Ä¢ Can still analyze Perplexity separately for citation patterns")
    print("   ‚ùå Cons:")
    print("     ‚Ä¢ Reduces sample size")
    print("     ‚Ä¢ Loses insights into AI-first search behavior")

    print("\n   OPTION 2: Create Separate Analysis Tracks")
    print("   ‚úÖ Pros:")
    print("     ‚Ä¢ Traditional SEO Analysis: Google AI + Bing AI")
    print("     ‚Ä¢ AI Citation Analysis: Perplexity only")
    print("     ‚Ä¢ Keeps all data while maintaining validity")
    print("   ‚ùå Cons:")
    print("     ‚Ä¢ More complex analysis")
    print("     ‚Ä¢ Need different metrics for each track")

    print("\n   OPTION 3: Reframe the Research Question")
    print("   ‚úÖ Pros:")
    print("     ‚Ä¢ Focus on 'content inclusion in AI responses' vs 'search ranking'")
    print("     ‚Ä¢ All engines become comparable on inclusion metrics")
    print("     ‚Ä¢ More relevant to AISO (AI Search Optimization)")
    print("   ‚ùå Cons:")
    print("     ‚Ä¢ Different from original SEO vs AISO framing")
    print("     ‚Ä¢ May need different feature analysis")

    print("\nüéØ RECOMMENDED APPROACH:")
    print("   DUAL-TRACK ANALYSIS:")
    print("   üìä Track 1: Traditional SEO Analysis")
    print("     ‚Ä¢ Engines: Google AI + Bing AI only")
    print("     ‚Ä¢ Focus: Page ranking, traditional SEO factors")
    print("     ‚Ä¢ Question: Do traditional SEO factors predict inclusion in AI Overviews?")
    print("   ")
    print("   ü§ñ Track 2: AI Citation Analysis")
    print("     ‚Ä¢ Engines: Perplexity (+ Google AI/Bing AI citations if available)")
    print("     ‚Ä¢ Focus: Citation selection, content quality factors")
    print("     ‚Ä¢ Question: What content characteristics get cited by AI systems?")

    print("\nüìã IMPLEMENTATION PLAN:")
    print("   1. Keep all existing code and data (as requested)")
    print("   2. Create separate analysis scripts:")
    print("      ‚Ä¢ analyze_traditional_seo.py (Google AI + Bing AI)")
    print("      ‚Ä¢ analyze_ai_citations.py (Perplexity focus)")
    print("      ‚Ä¢ analyze_combined_insights.py (synthesis)")
    print("   3. Update visualizations to reflect the dual-track approach")
    print("   4. Modify research questions to match the methodology")

def main():
    """Main analysis execution."""
    analyze_engine_structures()
    identify_fundamental_differences()
    create_comparison_plan()

    print("\n‚úÖ ANALYSIS COMPLETE")
    print("üìã Next Step: Review recommendations and decide on approach")

if __name__ == "__main__":
    main()